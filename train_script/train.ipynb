{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Iterable\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgt(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "        row = {\"input\": \"[(1, 10), (2, 20), (3, 30)]\", \"output\": \"[4, 5, 6]\"}\n",
    "        get_tgt(row)\n",
    "    \"\"\"\n",
    "    inputs = eval(row[\"input\"])\n",
    "    outputs = eval(row[\"output\"])\n",
    "    tgt_str_li = [f\"{list(input)}:{output},\" for input, output in zip(inputs, outputs)]\n",
    "    tgt_str = \"\".join(tgt_str_li)\n",
    "    tgt_str = tgt_str.replace(\" \", \"\")\n",
    "    tgt_str = tgt_str[:-1]\n",
    "    return tgt_str\n",
    "\n",
    "\n",
    "\n",
    "def build_vocab(strings: Iterable[str]):\n",
    "    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n",
    "    idx = 3\n",
    "    for sentence in strings:\n",
    "        for token in sentence:\n",
    "            if token not in vocab:\n",
    "                vocab[token] = idx\n",
    "                idx += 1\n",
    "    return vocab\n",
    "\n",
    "def id2token(vocab: dict[int, str], id: int) -> str:\n",
    "    for token, idx in vocab.items():\n",
    "        if idx == id:\n",
    "            return token\n",
    "    return None\n",
    "\n",
    "\n",
    "def tokenize(string: str, vocab: dict[str, int]) -> list[int]:\n",
    "    return [vocab[\"<sos>\"]] + [vocab[token] for token in string] + [vocab[\"<eos>\"]]\n",
    "\n",
    "class TransformerDataset(Dataset):\n",
    "    def __init__(self, dataframe, src_vocab, tgt_vocab, src_max_len, tgt_max_len):\n",
    "        self.dataframe = dataframe\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.src_max_len = src_max_len\n",
    "        self.tgt_max_len = tgt_max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def pad_sequence(self, seq, vocab, max_len):\n",
    "        return seq + [vocab[\"<pad>\"]] * (max_len - len(seq))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        src_tokens = tokenize(row['src_str'], self.src_vocab)\n",
    "        tgt_tokens = tokenize(row['tgt_str'], self.tgt_vocab)\n",
    "        src_padded = self.pad_sequence(src_tokens[:self.src_max_len], self.src_vocab, self.src_max_len)\n",
    "        tgt_padded = self.pad_sequence(tgt_tokens[:self.tgt_max_len], self.tgt_vocab, self.tgt_max_len)\n",
    "        return torch.tensor(src_padded), torch.tensor(tgt_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "data_path = \"/home/takeru/AlphaSymbol/data/prfndim/d3-a2-c3-r3-status.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df_data = pd.DataFrame(columns=[\"src\", \"tgt\"])\n",
    "\n",
    "df_data[\"tgt_str\"] = df[\"expr\"].apply(lambda x: x.replace(\" \", \"\"))\n",
    "df_data[\"src_str\"] = df.apply(get_tgt, axis=1)\n",
    "src_vocab = build_vocab(df_data[\"src_str\"])\n",
    "tgt_vocab = build_vocab(df_data[\"tgt_str\"])\n",
    "src_max_len = df_data[\"src_str\"].apply(len).max()\n",
    "tgt_max_len = df_data[\"tgt_str\"].apply(len).max()\n",
    "dataset = TransformerDataset(df_data, src_vocab, tgt_vocab, src_max_len, tgt_max_len)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 2.3948116643088206\n",
      "Epoch 2/100, Loss: 2.1350086757114957\n",
      "Epoch 3/100, Loss: 2.051949347768511\n",
      "Epoch 4/100, Loss: 1.5828802755900793\n",
      "Epoch 5/100, Loss: 1.0510199325425285\n",
      "Epoch 6/100, Loss: 0.8737418140683856\n",
      "Epoch 7/100, Loss: 0.8305619359016418\n",
      "Epoch 8/100, Loss: 0.7557384456907\n",
      "Epoch 9/100, Loss: 0.664957617010389\n",
      "Epoch 10/100, Loss: 0.6888793366295951\n",
      "Epoch 11/100, Loss: 0.6522269419261387\n",
      "Epoch 12/100, Loss: 0.6749982833862305\n",
      "Epoch 13/100, Loss: 0.6490717530250549\n",
      "Epoch 14/100, Loss: 0.5388032112802777\n",
      "Epoch 15/100, Loss: 0.5663161788667951\n",
      "Epoch 16/100, Loss: 0.5232447470937457\n",
      "Epoch 17/100, Loss: 0.47398244057382855\n",
      "Epoch 18/100, Loss: 0.4459611986364637\n",
      "Epoch 19/100, Loss: 0.4665420012814658\n",
      "Epoch 20/100, Loss: 0.407229197876794\n",
      "Epoch 21/100, Loss: 0.424311671938215\n",
      "Epoch 22/100, Loss: 0.4018236781869616\n",
      "Epoch 23/100, Loss: 0.4479578265122005\n",
      "Epoch 24/100, Loss: 0.4496226225580488\n",
      "Epoch 25/100, Loss: 0.42390948108264376\n",
      "Epoch 26/100, Loss: 0.3929436036518642\n",
      "Epoch 27/100, Loss: 0.34678989010197775\n",
      "Epoch 28/100, Loss: 0.3772296522344862\n",
      "Epoch 29/100, Loss: 0.3986279368400574\n",
      "Epoch 30/100, Loss: 0.4062583957399641\n",
      "Epoch 31/100, Loss: 0.43706112248556955\n",
      "Epoch 32/100, Loss: 0.37914834703717915\n",
      "Epoch 33/100, Loss: 0.3691464832850865\n",
      "Epoch 34/100, Loss: 0.33016409405640196\n",
      "Epoch 35/100, Loss: 0.349072733095714\n",
      "Epoch 36/100, Loss: 0.29192966648510527\n",
      "Epoch 37/100, Loss: 0.3354523096765791\n",
      "Epoch 38/100, Loss: 0.3309678775923593\n",
      "Epoch 39/100, Loss: 0.31685427682740347\n",
      "Epoch 40/100, Loss: 0.27261650775160107\n",
      "Epoch 41/100, Loss: 0.2886352390050888\n",
      "Epoch 42/100, Loss: 0.2787913850375584\n",
      "Epoch 43/100, Loss: 0.27851601796490805\n",
      "Epoch 44/100, Loss: 0.2870471775531769\n",
      "Epoch 45/100, Loss: 0.2821884666170393\n",
      "Epoch 46/100, Loss: 0.28243354175771984\n",
      "Epoch 47/100, Loss: 0.26253429480961393\n",
      "Epoch 48/100, Loss: 0.24974916875362396\n",
      "Epoch 49/100, Loss: 0.2610162603003638\n",
      "Epoch 50/100, Loss: 0.25049488459314617\n",
      "Epoch 51/100, Loss: 0.2517650787319456\n",
      "Epoch 52/100, Loss: 0.21415109932422638\n",
      "Epoch 53/100, Loss: 0.21837024177823747\n",
      "Epoch 54/100, Loss: 0.19555469921657018\n",
      "Epoch 55/100, Loss: 0.22237518216882432\n",
      "Epoch 56/100, Loss: 0.2029508841889245\n",
      "Epoch 57/100, Loss: 0.1978000338588442\n",
      "Epoch 58/100, Loss: 0.20295322792870657\n",
      "Epoch 59/100, Loss: 0.18930653589112417\n",
      "Epoch 60/100, Loss: 0.1919139495917729\n",
      "Epoch 61/100, Loss: 0.17665243361677443\n",
      "Epoch 62/100, Loss: 0.20931571934904372\n",
      "Epoch 63/100, Loss: 0.20318878761359624\n",
      "Epoch 64/100, Loss: 0.21869821207863943\n",
      "Epoch 65/100, Loss: 0.27602399247033255\n",
      "Epoch 66/100, Loss: 0.2589975489037378\n",
      "Epoch 67/100, Loss: 0.25734049720423563\n",
      "Epoch 68/100, Loss: 0.21370577812194824\n",
      "Epoch 69/100, Loss: 0.19443648840699876\n",
      "Epoch 70/100, Loss: 0.19345503619738988\n",
      "Epoch 71/100, Loss: 0.19584696846348898\n",
      "Epoch 72/100, Loss: 0.2108156191451209\n",
      "Epoch 73/100, Loss: 0.2102596504347665\n",
      "Epoch 74/100, Loss: 0.20941748363631113\n",
      "Epoch 75/100, Loss: 0.1994288989475795\n",
      "Epoch 76/100, Loss: 0.19405658117362432\n",
      "Epoch 77/100, Loss: 0.168196117239339\n",
      "Epoch 78/100, Loss: 0.1840718218258449\n",
      "Epoch 79/100, Loss: 0.17076806617634638\n",
      "Epoch 80/100, Loss: 0.16268375515937805\n",
      "Epoch 81/100, Loss: 0.1577514899628503\n",
      "Epoch 82/100, Loss: 0.21051023261887686\n",
      "Epoch 83/100, Loss: 0.1807128382580621\n",
      "Epoch 84/100, Loss: 0.1533989714724677\n",
      "Epoch 85/100, Loss: 0.16139596168484008\n",
      "Epoch 86/100, Loss: 0.15705829220158712\n",
      "Epoch 87/100, Loss: 0.15873437374830246\n",
      "Epoch 88/100, Loss: 0.14099879137107305\n",
      "Epoch 89/100, Loss: 0.14590260812214442\n",
      "Epoch 90/100, Loss: 0.16301500797271729\n",
      "Epoch 91/100, Loss: 0.13977897805827005\n",
      "Epoch 92/100, Loss: 0.15544888802937099\n",
      "Epoch 93/100, Loss: 0.1967555018407958\n",
      "Epoch 94/100, Loss: 0.1480321948017393\n",
      "Epoch 95/100, Loss: 0.18439870114837373\n",
      "Epoch 96/100, Loss: 0.17169560492038727\n",
      "Epoch 97/100, Loss: 0.14919660559722356\n",
      "Epoch 98/100, Loss: 0.15668850924287522\n",
      "Epoch 99/100, Loss: 0.146661571093968\n",
      "Epoch 100/100, Loss: 0.17808111437729426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)  # Add batch dimension\n",
    "        self.encoding = self.encoding.permute(1, 0, 2)  # (max_len, batch_size, d_model)\n",
    "        self.register_buffer(\"pe\", self.encoding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (seq_len, batch_size, d_model)\n",
    "        \"\"\"\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.pe[: seq_len]\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, src_max_len, tgt_max_len, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.d_model = d_model\n",
    "        self.src_pos_enc = PositionalEncoding(d_model, src_max_len)\n",
    "        self.tgt_pos_enc = PositionalEncoding(d_model, tgt_max_len)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.src_embedding(src) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        tgt = self.tgt_embedding(tgt) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        src = src.permute(1, 0, 2)  # (S, N, E)\n",
    "        tgt = tgt.permute(1, 0, 2)  # (T, N, E)\n",
    "        src = src + self.src_pos_enc(src)\n",
    "        tgt = tgt + self.tgt_pos_enc(tgt)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(0))\n",
    "        output = self.transformer(src, tgt, tgt_mask = tgt_mask)\n",
    "        output = self.fc_out(output)\n",
    "        return output\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "src_vocab_size = len(src_vocab)\n",
    "tgt_vocab_size = len(tgt_vocab)\n",
    "model = TransformerModel(src_vocab_size, tgt_vocab_size, src_max_len, tgt_max_len)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=src_vocab[\"<pad>\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src_batch, tgt_batch in dataloader:\n",
    "        tgt_input = tgt_batch[:, :-1]\n",
    "        tgt_output = tgt_batch[:, 1:]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(src_batch, tgt_input)\n",
    "        output = output.permute(1, 2, 0)  # (N, C, T)\n",
    "        loss = criterion(output, tgt_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4,\n",
      "        7, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4,\n",
      "        7, 3, 4, 5, 6, 4, 7, 3, 4, 5, 6, 4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "C\n",
      "(\n",
      "C\n",
      "(\n",
      "Z\n",
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "c = \"<sos>\"\n",
    "data = dataset[0][0]\n",
    "print(data)\n",
    "while c !=\"<eos>\":\n",
    "    ret = model(data.unsqueeze(0), torch.tensor(tgt_vocab[c]).unsqueeze(0).unsqueeze(0))\n",
    "    c = id2token(tgt_vocab, ret.squeeze().argmax().item())\n",
    "    print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
