{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import LitTransformer\n",
    "import torch\n",
    "import yaml\n",
    "from data import get_tgt_str, build_vocab, id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<sos>', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']\n"
     ]
    }
   ],
   "source": [
    "config_path = \"/home/takeru/AlphaSymbol/models/config_20241206174837.yaml\"\n",
    "state_dict = \"/home/takeru/AlphaSymbol/models/model_30000epochs_20241206182634.pth\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "src_max_len = config[\"src_max_len\"]\n",
    "tgt_max_len = config[\"tgt_max_len\"]\n",
    "src_vocab = config[\"src_vocab\"]\n",
    "tgt_vocab = config[\"tgt_vocab\"]\n",
    "\n",
    "model = LitTransformer(len(src_vocab), len(tgt_vocab), src_max_len, tgt_max_len,\n",
    "        d_model=64,\n",
    "        nhead=4,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        dim_feedforward=512,\n",
    "        dropout=0.1,)\n",
    "\n",
    "inputs = [(0,), (1,), (2,), (3,), (4,), (5,), (6,), (7,), (8,), (9,)]\n",
    "#outputs = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "#outputs = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "outputs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "src_str = get_tgt_str(inputs, outputs)\n",
    "src_tensor = torch.tensor([src_vocab[i] for i in src_str])\n",
    "src_tensor = torch.cat([src_tensor, torch.tensor([src_vocab[\"<pad>\"] for _ in range(src_max_len - src_tensor.shape[0])])])\n",
    "src_tensor = src_tensor.unsqueeze(0)\n",
    "out_str = torch.tensor(tgt_vocab[\"<sos>\"]).reshape((1, ))\n",
    "out_str = out_str.unsqueeze(0)\n",
    "\n",
    "model.load_state_dict(torch.load(state_dict, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(tgt_max_len):\n",
    "        pred = model(src_tensor, out_str)\n",
    "        next_c = pred[0, -1, :]\n",
    "        max_values, max_indices = torch.max(next_c, axis=0)\n",
    "        out_str = torch.cat((out_str, max_indices.reshape(1, 1)), axis=1)\n",
    "        if max_indices == tgt_vocab[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "print([id2token(tgt_vocab, id) for id in out_str[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
