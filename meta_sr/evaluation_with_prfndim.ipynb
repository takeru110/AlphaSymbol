{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bf3ccd4-bd5a-4b9b-896c-fb97393263c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import os, sys\n",
    "import symbolicregression\n",
    "import requests\n",
    "from IPython.display import display\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839ef0a2",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41d28548",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = 100\n",
    "csv_path = \"/home/takeru/AlphaSymbol/temp/d5-a3-c2-r3-stopped-random-points-test10k-crop10-test.csv\"\n",
    "tolerances = [0, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6777244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the R2 score.\n",
    "    R2 = 1 - (Σ(y_i - ŷ_i)^2) / (Σ(y_i - ȳ)^2)\n",
    "\n",
    "    Args:\n",
    "    - y_true (list[float]): Ground truth values\n",
    "    - y_pred (list[float]): Predicted values\n",
    "\n",
    "    Returns:\n",
    "    - float: R2 score\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    numerator = np.sum((y_true - y_pred) ** 2)\n",
    "    denominator = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "\n",
    "    # Handle pathological cases\n",
    "    if denominator == 0:\n",
    "        return 0.0  # No variance in y_true\n",
    "    return 1 - numerator / denominator\n",
    "\n",
    "\n",
    "def inlier_rate(y_true, y_pred, tau):\n",
    "    \"\"\"\n",
    "    Compute the accuracy within tolerance τ.\n",
    "    Accτ = 1(max(|(ŷ_i - y_i) / y_i|) <= τ)\n",
    "\n",
    "    Args:\n",
    "    - y_true (list[float]): Ground truth values\n",
    "    - y_pred (list[float]): Predicted values\n",
    "    - tau (float): Tolerance threshold\n",
    "\n",
    "    Returns:\n",
    "    - int: 1 if the maximum relative error is within tolerance, else 0\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # Avoid division by zero; filter out y_true == 0\n",
    "    non_zero_indices = y_true != 0\n",
    "    if not non_zero_indices.any():\n",
    "        return 0  # If all y_true are zero, return 0\n",
    "\n",
    "    relative_errors = np.abs(\n",
    "        (y_pred[non_zero_indices] - y_true[non_zero_indices])\n",
    "    )\n",
    "    num_inlier = sum(relative_errors <= tau)\n",
    "    return int(num_inlier) / len(y_true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d760e6c",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52a6b685-a1ed-4cb5-975d-f1bd316ec778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Model successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model.pt\" \n",
    "try:\n",
    "    if not os.path.isfile(model_path): \n",
    "        url = \"https://dl.fbaipublicfiles.com/symbolicregression/model1.pt\"\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(model_path, 'wb').write(r.content)\n",
    "    if not torch.cuda.is_available():\n",
    "        model = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    else:\n",
    "        model = torch.load(model_path)\n",
    "        model = model.cuda()\n",
    "    print(model.device)\n",
    "    print(\"Model successfully loaded!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"ERROR: model not loaded! path was: {}\".format(model_path))\n",
    "    print(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb5ebd8c-235e-4051-87a4-acbafadf937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "est = symbolicregression.model.SymbolicTransformerRegressor(\n",
    "                        model=model,\n",
    "                        max_input_points=200,\n",
    "                        n_trees_to_refine=100,\n",
    "                        rescale=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218fb41",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699a062-41e6-4747-87ce-1e75a2496b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)\n",
    "# the index of lists are sample number\n",
    "acc_taus = {tau: [] for tau in tolerances}\n",
    "r2s = []\n",
    "assert df[\"n_points\"].max() > n_points\n",
    "for i, (\n",
    "        input_str,\n",
    "        output_str,\n",
    "        correct_expr,\n",
    "        test_input_str,\n",
    "        test_output_str,\n",
    "    ) in enumerate(\n",
    "        zip(\n",
    "            df[\"input\"],\n",
    "            df[\"output\"],\n",
    "            df[\"expr\"],\n",
    "            df[\"test_input\"],\n",
    "            df[\"test_output\"],\n",
    "        ),\n",
    "    ):\n",
    "\n",
    "    print(\"\\n\")\n",
    "    x = np.array(eval(input_str)[:n_points])\n",
    "    y = np.array(eval(output_str)[:n_points])\n",
    "    print(\"The number of points for regression: \", len(x))\n",
    "    test_input, test_output = eval(test_input_str), eval(test_output_str)\n",
    "    print(f\"Input points: {test_input}\")\n",
    "    print(f\"Correct output: {test_output}\")\n",
    "    est.fit(x,y)\n",
    "    replace_ops = {\"add\": \"+\", \"mul\": \"*\", \"sub\": \"-\", \"pow\": \"**\", \"inv\": \"1/\"}\n",
    "    model_str = est.retrieve_tree(with_infos=True)[\"relabed_predicted_tree\"].infix()\n",
    "    for op,replace_op in replace_ops.items():\n",
    "        model_str = model_str.replace(op,replace_op)\n",
    "    #display(sp.parse_expr(model_str))\n",
    "    \n",
    "    # use function\n",
    "    x_0, x_1, x_2, x_3, x_4 = sp.symbols(\"x_0 x_1 x_2 x_3 x_4\")\n",
    "    local_dict = {\n",
    "        \"e\": sp.E,\n",
    "        \"pi\": sp.pi,\n",
    "        \"euler_gamma\": sp.EulerGamma,\n",
    "        \"arcsin\": sp.asin,\n",
    "        \"arccos\": sp.acos,\n",
    "        \"arctan\": sp.atan,\n",
    "        \"step\": sp.Heaviside,\n",
    "        \"sign\": sp.sign,\n",
    "    }\n",
    "    expr = parse_expr(model_str, evaluate=True, local_dict=local_dict)\n",
    "\n",
    "\n",
    "    print(f\"The number of points for testing: {len(test_input)}\")\n",
    "    pred_output = []\n",
    "    for xs, y in zip(test_input, test_output):\n",
    "        dict_vars = {f\"x_{i}\": x for i, x in enumerate(xs)}\n",
    "        pred_output.append(expr.subs(dict_vars))\n",
    "    print(f\"Predicted output: {pred_output}\")\n",
    "    \n",
    "    # calc r2\n",
    "    r2_score = compute_r2(test_output, pred_output)\n",
    "    r2s.append(r2_score)\n",
    "\n",
    "    # calc accuracy per sample\n",
    "    for tau in tolerances:\n",
    "        acc_tau = inlier_rate(test_output, pred_output, tau)\n",
    "        acc_taus[tau].append(acc_tau)\n",
    "\n",
    "r2 = np.mean(r2s)\n",
    "acc_tau = dict.fromkeys(tolerances, None)\n",
    "for tau in tolerances:\n",
    "    acc_tau[tau] = np.mean(acc_taus[tau])\n",
    "print(r2)\n",
    "print(acc_tau)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symbolic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
