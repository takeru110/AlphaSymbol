{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StrictPrfGame\n",
    "This code is written according to Pytorch tutorials.\n",
    "https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strict_prf_game import StrictPrfGame\n",
    "from strict_prf import Z, S, P, C, R, Expr\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from datetime import datetime\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.fix_gpu_env = True\n",
    "        self.device = \"cpu\" # \"auto\", \"gpu\", \"cpu\"\n",
    "        \n",
    "config = Config()\n",
    "\n",
    "\n",
    "if config.fix_gpu_env:\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "    os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "\n",
    "env = StrictPrfGame(\n",
    "    max_p_arity=2,\n",
    "    expr_depth=2,\n",
    "    max_c_args=2,\n",
    "    max_steps=10,\n",
    "    input_sequence=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    output_sequence=[3, 4, 5, 6, 7, 8, 9, 10, 11, 12],\n",
    "    n_obs=100,\n",
    "    init_expr=Z(),\n",
    ")\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "if config.device == \"auto\":\n",
    "    # if GPU is to be used\n",
    "    device = torch.device(\n",
    "        \"cuda\" if torch.cuda.is_available() else\n",
    "        \"mps\" if torch.backends.mps.is_available() else\n",
    "        \"cpu\"\n",
    "    )\n",
    "elif config.device == \"gpu\":\n",
    "    device = \"cuda\"\n",
    "elif config.device == \"cpu\":\n",
    "    device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \"\"\"Deque of Transition\"\"\"\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# EPS_START is the starting value of epsilon\n",
    "# EPS_END is the final value of epsilon\n",
    "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    # flatten the batch\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "    num_episodes = 100\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "outputs_dir = Path(\"log\")\n",
    "outputs_dir.mkdir(exist_ok=True)\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "date_dir = outputs_dir / current_date\n",
    "date_dir.mkdir(exist_ok=True)\n",
    "\n",
    "log_data = []\n",
    "    \n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "        \n",
    "        log_data.append({\n",
    "            \"Iteration\": env.step_count,\n",
    "            \"Input\": env.input_sequence,\n",
    "            \"Target\": env.output_sequence,\n",
    "            \"Formula\": env.current_expr,\n",
    "            \"Current Output\": env.current_output(),\n",
    "            \"Terminated\": terminated,\n",
    "            \"Truncated\": truncated,\n",
    "            \"Position\": info[\"position\"],\n",
    "            \"Substitute\": info[\"substitute\"]\n",
    "        })\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "\n",
    "log_df = pd.DataFrame(log_data)\n",
    "\n",
    "current_time = datetime.now().strftime(\"%H-%M-%S\")\n",
    "csv_file_path = date_dir / f\"{current_time}.csv\"\n",
    "log_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
